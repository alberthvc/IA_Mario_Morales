{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c774c713",
   "metadata": {},
   "source": [
    "## Descripción del dataset: Pima Indians Diabetes\n",
    "\n",
    "El **Pima Indians Diabetes Dataset** es un conjunto de datos clásico en Machine Learning y bioestadística, recopilado por el *National Institute of Diabetes and Digestive and Kidney Diseases*.  \n",
    "Su propósito es **predecir la aparición de diabetes tipo 2** en mujeres de origen **pima** (una población indígena del sur de Arizona, EE.UU.), a partir de diversas variables clínicas y demográficas.\n",
    "\n",
    "### Características principales:\n",
    "- **Número de registros:** 392 (en esta versión limpia, el original tenía 768).  \n",
    "- **Número de atributos (features):** 8 variables predictoras + 1 variable objetivo.  \n",
    "- **Población:** Mujeres de al menos 21 años de edad de la etnia Pima.  \n",
    "- **Tarea principal:** Clasificación binaria → determinar si una paciente tiene diabetes (`Outcome = 1`) o no (`Outcome = 0`).\n",
    "\n",
    "### Variables:\n",
    "1. **Pregnancies** → Número de embarazos.  \n",
    "2. **Glucose** → Concentración de glucosa en plasma después de 2 horas en una prueba de tolerancia a la glucosa.  \n",
    "3. **BloodPressure** → Presión arterial diastólica (mm Hg).  \n",
    "4. **SkinThickness** → Espesor del pliegue cutáneo del tríceps (mm).  \n",
    "5. **Insulin** → Nivel sérico de insulina (mu U/ml).  \n",
    "6. **BMI** → Índice de masa corporal (peso en kg / altura² en m²).  \n",
    "7. **DiabetesPedigreeFunction** → Probabilidad de diabetes basada en antecedentes familiares.  \n",
    "8. **Age** → Edad en años.  \n",
    "9. **Outcome** → Variable objetivo:  \n",
    "   - `0` = No tiene diabetes  \n",
    "   - `1` = Tiene diabetes  \n",
    "\n",
    "### Relevancia:\n",
    "Este dataset es ampliamente utilizado en cursos de **Inteligencia Artificial y Machine Learning** para enseñar:\n",
    "- Procesamiento y limpieza de datos biomédicos.  \n",
    "- Métodos de clasificación supervisada (KNN, regresión logística, Random Forest, SVM, redes neuronales, etc.).  \n",
    "- Importancia de la normalización y estandarización en algoritmos basados en distancias.  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e89ef96",
   "metadata": {},
   "source": [
    "## Paso 1: Cargar la base de datos  \n",
    "Cargamos el CSV en un `DataFrame` de `pandas`. Si tu archivo no se llama exactamente `cleaned_dataset.csv`, ajusta la ruta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17934010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Blood Pressure</th>\n",
       "      <th>Skin Thickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Diabetes Pedigree Function</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>110</td>\n",
       "      <td>46</td>\n",
       "      <td>130</td>\n",
       "      <td>67.1</td>\n",
       "      <td>0.319</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>78</td>\n",
       "      <td>63</td>\n",
       "      <td>14</td>\n",
       "      <td>59.4</td>\n",
       "      <td>2.420</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>123</td>\n",
       "      <td>100</td>\n",
       "      <td>35</td>\n",
       "      <td>240</td>\n",
       "      <td>57.3</td>\n",
       "      <td>0.880</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>30</td>\n",
       "      <td>42</td>\n",
       "      <td>99</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.496</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>76</td>\n",
       "      <td>56</td>\n",
       "      <td>100</td>\n",
       "      <td>53.2</td>\n",
       "      <td>0.759</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>165</td>\n",
       "      <td>90</td>\n",
       "      <td>33</td>\n",
       "      <td>680</td>\n",
       "      <td>52.3</td>\n",
       "      <td>0.427</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>122</td>\n",
       "      <td>90</td>\n",
       "      <td>51</td>\n",
       "      <td>220</td>\n",
       "      <td>49.7</td>\n",
       "      <td>0.325</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>165</td>\n",
       "      <td>76</td>\n",
       "      <td>43</td>\n",
       "      <td>255</td>\n",
       "      <td>47.9</td>\n",
       "      <td>0.259</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>88</td>\n",
       "      <td>60</td>\n",
       "      <td>110</td>\n",
       "      <td>46.8</td>\n",
       "      <td>0.962</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>81</td>\n",
       "      <td>78</td>\n",
       "      <td>40</td>\n",
       "      <td>48</td>\n",
       "      <td>46.7</td>\n",
       "      <td>0.261</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  Blood Pressure  Skin Thickness  Insulin   BMI  \\\n",
       "0            0      129             110              46      130  67.1   \n",
       "1            0      180              78              63       14  59.4   \n",
       "2            3      123             100              35      240  57.3   \n",
       "3            1       88              30              42       99  55.0   \n",
       "4            0      162              76              56      100  53.2   \n",
       "5            0      165              90              33      680  52.3   \n",
       "6            1      122              90              51      220  49.7   \n",
       "7            0      165              76              43      255  47.9   \n",
       "8            0      100              88              60      110  46.8   \n",
       "9            7       81              78              40       48  46.7   \n",
       "\n",
       "   Diabetes Pedigree Function  Age  Outcome  \n",
       "0                       0.319   26        1  \n",
       "1                       2.420   25        1  \n",
       "2                       0.880   22        0  \n",
       "3                       0.496   26        1  \n",
       "4                       0.759   25        1  \n",
       "5                       0.427   23        0  \n",
       "6                       0.325   31        1  \n",
       "7                       0.259   26        0  \n",
       "8                       0.962   31        0  \n",
       "9                       0.261   42        0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el dataset limpio\n",
    "df = pd.read_csv('cleaned_dataset.csv')\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34b7ef2",
   "metadata": {},
   "source": [
    "## Paso 2: Crear subconjuntos con 20 datos de **entrenamiento** y 20 de **testeo**\n",
    "Seleccionaremos 40 muestras: 20 para entrenar y 20 para evaluar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cce560c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento:\n",
      "     Pregnancies  Glucose  Blood Pressure  Skin Thickness  Insulin   BMI  \\\n",
      "78             2      146              76              35      194  38.2   \n",
      "274            7       83              78              26       71  29.3   \n",
      "246            0      120              74              18       63  30.5   \n",
      "55             0       91              68              32      210  39.9   \n",
      "387            1       92              62              25       41  19.5   \n",
      "203            3      174              58              22      194  32.9   \n",
      "42             0      152              82              39      272  41.5   \n",
      "233           10      125              70              26      115  31.1   \n",
      "150            0      177              60              29      478  34.6   \n",
      "116            0      127              80              37      210  36.3   \n",
      "9              7       81              78              40       48  46.7   \n",
      "208            2       87              58              16       52  32.7   \n",
      "287            1      130              60              23      170  28.6   \n",
      "165            9      152              78              34      171  34.2   \n",
      "275            6      154              74              32      193  29.3   \n",
      "362            1       95              60              18       58  23.9   \n",
      "124            0       84              64              22       66  35.8   \n",
      "351            2       99              52              15       94  24.6   \n",
      "294            3      130              78              23       79  28.4   \n",
      "332            7      124              70              33      215  25.5   \n",
      "\n",
      "     Diabetes Pedigree Function  Age  Outcome  \n",
      "78                        0.329   29        0  \n",
      "274                       0.767   36        0  \n",
      "246                       0.285   26        0  \n",
      "55                        0.381   25        0  \n",
      "387                       0.482   25        0  \n",
      "203                       0.593   36        1  \n",
      "42                        0.270   27        0  \n",
      "233                       0.205   41        1  \n",
      "150                       1.072   21        1  \n",
      "116                       0.804   23        0  \n",
      "9                         0.261   42        0  \n",
      "208                       0.166   25        0  \n",
      "287                       0.692   21        0  \n",
      "165                       0.893   33        1  \n",
      "275                       0.839   39        0  \n",
      "362                       0.260   22        0  \n",
      "124                       0.545   21        0  \n",
      "351                       0.637   21        0  \n",
      "294                       0.323   34        1  \n",
      "332                       0.161   37        0  \n",
      "\n",
      "Testeo:\n",
      "     Pregnancies  Glucose  Blood Pressure  Skin Thickness  Insulin   BMI  \\\n",
      "310            1       90              62              12       43  27.2   \n",
      "127            3      173              84              33      474  35.7   \n",
      "329            5      166              72              19      175  25.8   \n",
      "75             3      173              82              48      465  38.4   \n",
      "213            7      133              88              15      155  32.4   \n",
      "38            11      120              80              37      150  42.3   \n",
      "173            8      155              62              26      495  34.0   \n",
      "64            12      140              82              43      325  39.2   \n",
      "354            1      125              70              24      110  24.3   \n",
      "121            2      122              76              27      200  35.9   \n",
      "20             0      117              80              31       53  45.2   \n",
      "308            4      129              60              12      231  27.5   \n",
      "101            5      105              72              29      325  36.9   \n",
      "26             1       79              60              42       48  43.5   \n",
      "159            1      112              72              30      176  34.4   \n",
      "32             3      120              70              30      135  42.9   \n",
      "161            0      121              66              30      165  34.3   \n",
      "319            1      143              74              22       61  26.2   \n",
      "389            1      103              80              11       82  19.4   \n",
      "374            4      116              72              12       87  22.1   \n",
      "\n",
      "     Diabetes Pedigree Function  Age  Outcome  \n",
      "310                       0.580   24        0  \n",
      "127                       0.258   22        1  \n",
      "329                       0.587   51        1  \n",
      "75                        2.137   25        1  \n",
      "213                       0.262   37        0  \n",
      "38                        0.785   48        1  \n",
      "173                       0.543   46        1  \n",
      "64                        0.528   58        1  \n",
      "354                       0.221   25        0  \n",
      "121                       0.483   26        0  \n",
      "20                        0.089   24        0  \n",
      "308                       0.527   31        0  \n",
      "101                       0.159   28        0  \n",
      "26                        0.678   23        0  \n",
      "159                       0.528   25        0  \n",
      "32                        0.452   30        0  \n",
      "161                       0.203   33        1  \n",
      "319                       0.256   21        0  \n",
      "389                       0.491   22        0  \n",
      "374                       0.463   37        0  \n"
     ]
    }
   ],
   "source": [
    "#codigo aqui\n",
    "# Seleccionar 20 muestras para entrenamiento y 20 para testeo\n",
    "train_df = df.sample(n=20, random_state=42)\n",
    "test_df = df.drop(train_df.index).sample(n=20, random_state=24)\n",
    "\n",
    "# Mostrar los subconjuntos\n",
    "print(\"Entrenamiento:\")\n",
    "print(train_df)\n",
    "print(\"\\nTesteo:\")\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b1e8d1",
   "metadata": {},
   "source": [
    "## Paso 3: Implementar la función de distancia euclidiana\n",
    "\n",
    "**Instrucciones:**\n",
    "- Escribe una función en Python que reciba dos vectores y calcule la distancia euclidiana entre ellos.\n",
    "- Utiliza la siguiente fórmula matemática para la distancia euclidiana entre dos vectores $x$ y $y$ de $n$ dimensiones:\n",
    "\n",
    "$$\n",
    "d(x, y) = \\sqrt{\\sum_{i=1}^{n} (x_i - y_i)^2}\n",
    "$$\n",
    "\n",
    "- Prueba tu función con los siguientes dos ejemplos (cada vector corresponde a una fila del dataset):\n",
    "\n",
    "| Embarazos | Glucosa | Presión Arterial | Grosor Piel | Insulina | IMC  | Función Hereditaria | Edad | Resultado |\n",
    "|-----------|---------|------------------|-------------|----------|------|---------------------|------|-----------|\n",
    "|     1     |   106   |        70        |      28     |   135    | 34.2 |        0.142        |  22  |     0     |\n",
    "|     2     |   102   |        86        |      36     |   120    | 45.5 |        0.127        |  23  |     1     |\n",
    "\n",
    "- Calcula la distancia euclidiana a mano y luego verifica que el resultado de tu función sea el mismo.\n",
    "- La función debe imprimir el resultado del cálculo de la distancia euclidiana con los datos presentados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f46e2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distancia euclidiana entre los dos ejemplos: 26.3000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def euclidean_distance(x, y):\n",
    "    \"\"\"\n",
    "    Calcula la distancia euclidiana entre dos vectores x e y.\n",
    "    \"\"\"\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    distance = np.sqrt(np.sum((x - y) ** 2))\n",
    "    return distance\n",
    "\n",
    "# Ejemplo con los dos vectores dados\n",
    "vector1 = [1, 106, 70, 28, 135, 34.2, 0.142, 22, 0]\n",
    "vector2 = [2, 102, 86, 36, 120, 45.5, 0.127, 23, 1]\n",
    "\n",
    "dist = euclidean_distance(vector1, vector2)\n",
    "print(f\"Distancia euclidiana entre los dos ejemplos: {dist:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc73bbcc",
   "metadata": {},
   "source": [
    "## Paso 4: Implementar un clasificador KNN básico\n",
    "\n",
    "**Instrucciones:**\n",
    "- Escribe una función que, dado un punto de prueba, calcule la distancia a todos los puntos de entrenamiento utilizando tu función de distancia euclidiana.\n",
    "- Selecciona los **k = 3** vecinos más cercanos y predice la clase mayoritaria entre ellos.\n",
    "- Aplica tu función a las 10 muestras de prueba obtenidas previamente, utilizando las 10 muestras de entrenamiento como referencia.\n",
    "- El script debe imprimir una tabla comparando el valor real de `Resultado` de cada muestra de prueba con el valor predicho por tu algoritmo.\n",
    "- Considere que las tablas se pueden codificar con un formato similar al que se muestra en el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70345de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Index  Real  Predicho\n",
      "0     310   0.0       0.0\n",
      "1     127   1.0       0.0\n",
      "2     329   1.0       1.0\n",
      "3      75   1.0       0.0\n",
      "4     213   0.0       1.0\n",
      "5      38   1.0       1.0\n",
      "6     173   1.0       0.0\n",
      "7      64   1.0       0.0\n",
      "8     354   0.0       1.0\n",
      "9     121   0.0       0.0\n",
      "10     20   0.0       0.0\n",
      "11    308   0.0       0.0\n",
      "12    101   0.0       0.0\n",
      "13     26   0.0       0.0\n",
      "14    159   0.0       0.0\n",
      "15     32   0.0       1.0\n",
      "16    161   1.0       0.0\n",
      "17    319   0.0       0.0\n",
      "18    389   0.0       0.0\n",
      "19    374   0.0       0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Paso 4: Implementar un clasificador KNN básico (k=3) usando las funciones y subconjuntos previos\n",
    "\n",
    "def knn_predict(test_df, train_df, k=3):\n",
    "    # Usar solo las columnas de características (sin 'Outcome')\n",
    "    feature_cols = [col for col in train_df.columns if col != 'Outcome']\n",
    "    predictions = []\n",
    "    results = []\n",
    "\n",
    "    for idx, test_row in test_df.iterrows():\n",
    "        test_vector = test_row[feature_cols].values\n",
    "\n",
    "        # Calcular distancia a cada punto de entrenamiento\n",
    "        distances = []\n",
    "        for _, train_row in train_df.iterrows():\n",
    "            train_vector = train_row[feature_cols].values\n",
    "            dist = euclidean_distance(test_vector, train_vector)\n",
    "            distances.append((dist, train_row['Outcome']))\n",
    "\n",
    "        # Seleccionar los k vecinos más cercanos\n",
    "        distances.sort(key=lambda x: x[0])\n",
    "        k_neighbors = distances[:k]\n",
    "        neighbor_outcomes = [outcome for _, outcome in k_neighbors]\n",
    "\n",
    "        # Predicción: clase mayoritaria\n",
    "        pred = max(set(neighbor_outcomes), key=neighbor_outcomes.count)\n",
    "        predictions.append(pred)\n",
    "        results.append({\n",
    "            'Index': idx,\n",
    "            'Real': test_row['Outcome'],\n",
    "            'Predicho': pred\n",
    "        })\n",
    "\n",
    "    # Mostrar tabla comparativa\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(results_df)\n",
    "\n",
    "knn_predict(test_df, train_df, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494f7f05",
   "metadata": {},
   "source": [
    "## Paso 5: Usar toda la data con separación 80% entrenamiento / 20% testeo  \n",
    "\n",
    "### Pasos:\n",
    "1. Cargar todo el dataset.  \n",
    "2. Separar variables (X) y etiquetas (y).  \n",
    "3. Aplicar `train_test_split` con 80% para entrenamiento y 20% para testeo.  \n",
    "4. Mantener la proporción de clases usando estratificación.  \n",
    "5. Guardar los conjuntos de datos para usarlos en KNN.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "632f81a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño entrenamiento: (313, 8)\n",
      "Tamaño testeo: (79, 8)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separar variables (X) y etiquetas (y)\n",
    "X = df.drop('Outcome', axis=1)\n",
    "y = df['Outcome']\n",
    "\n",
    "# Separar 80% entrenamiento y 20% testeo, con estratificación\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Guardar los conjuntos para usarlos en KNN\n",
    "print(\"Tamaño entrenamiento:\", X_train.shape)\n",
    "print(\"Tamaño testeo:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb071d8",
   "metadata": {},
   "source": [
    "## Paso 6: Entrenar un KNN con los datos sin escalar (crudos) y calcular accuracy  \n",
    "\n",
    "### Pasos:\n",
    "1. Definir el valor de **k = 3** y el metodo **Euclidiano**.  \n",
    "2. Entrenar el modelo KNN con los datos crudos (sin normalizar/estandarizar).  \n",
    "3. Predecir las clases del conjunto de test.  \n",
    "4. Calcular el **accuracy** comparando predicciones con etiquetas reales.  \n",
    "5. Guardar el resultado para la tabla comparativa.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24573fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy KNN datos crudos: 0.8101\n"
     ]
    }
   ],
   "source": [
    "# Paso 6: Entrenar un KNN manual con datos crudos y calcular accuracy\n",
    "\n",
    "# 1. Definir k=3 y usar distancia euclidiana\n",
    "k = 3  # <-- Punto 1\n",
    "\n",
    "def knn_predict_manual(X_train, y_train, X_test, k=3):\n",
    "    predictions = []\n",
    "    train_vectors = X_train.values\n",
    "    train_labels = y_train.values\n",
    "\n",
    "    # 2. Para cada muestra de test, calcular distancia a todos los puntos de entrenamiento\n",
    "    for test_vector in X_test.values:  # <-- Punto 2\n",
    "        distances = np.sqrt(np.sum((train_vectors - test_vector) ** 2, axis=1))\n",
    "        \n",
    "        # 3. Seleccionar los k vecinos más cercanos\n",
    "        k_indices = np.argsort(distances)[:k]  # <-- Punto 3\n",
    "        k_labels = train_labels[k_indices]\n",
    "        \n",
    "        # 4. Predicción: clase mayoritaria entre los vecinos\n",
    "        pred = np.bincount(k_labels).argmax()  # <-- Punto 4\n",
    "        predictions.append(pred)\n",
    "    return np.array(predictions)\n",
    "\n",
    "# 5. Predecir sobre el conjunto de test y calcular accuracy  <-- Punto 5\n",
    "y_pred_crudo = knn_predict_manual(X_train, y_train, X_test, k=k)\n",
    "accuracy_crudo = (y_pred_crudo == y_test.values).mean()\n",
    "print(f\"Accuracy KNN datos crudos: {accuracy_crudo:.4f}\")  # <-- Punto 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82664821",
   "metadata": {},
   "source": [
    "## Paso 7: Normalizar (Min-Max scaling) y entrenar KNN, luego calcular accuracy  \n",
    "\n",
    "### Pasos:\n",
    "1. Aplicar **normalización Min-Max** a los datos de entrenamiento y test.  \n",
    "2. Entrenar el modelo KNN con los datos normalizados.  \n",
    "3. Predecir las clases del conjunto de test.  \n",
    "4. Calcular el **accuracy** del modelo.  \n",
    "5. Guardar el resultado para la tabla comparativa.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fee878bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy KNN datos normalizados: 0.7342\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Paso 7: Normalizar (Min-Max scaling) y entrenar KNN, luego calcular accuracy\n",
    "\n",
    "# 1. Aplicar normalización Min-Max a los datos de entrenamiento y test\n",
    "train_vectors = X_train.values\n",
    "scaler = MinMaxScaler()\n",
    "X_train_norm = scaler.fit_transform(X_train)  # <-- Punto 1\n",
    "X_test_norm = scaler.transform(X_test)        # <-- Punto 1\n",
    "\n",
    "# 2. Entrenar el modelo KNN manual con los datos normalizados\n",
    "y_pred_norm = knn_predict_manual(X_train_norm, y_train.values.astype(int), X_test_norm, k=k) # <-- Punto 2\n",
    "\n",
    "# 3. Calcular el accuracy comparando predicciones con etiquetas reales\n",
    "accuracy_norm = (y_pred_norm == y_test.values).mean()  # <-- Punto 3\n",
    "\n",
    "# 4. Imprimir el resultado del accuracy\n",
    "print(f\"Accuracy KNN datos normalizados: {accuracy_norm:.4f}\")  # <-- Punto 4\n",
    "\n",
    "# 5. Guardar el resultado para la tabla comparativa\n",
    "accuracy_normalizado = accuracy_norm  # <-- Punto 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9302c238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_predict_manual(X_train, y_train, X_test, k=3):\n",
    "    predictions = []\n",
    "    # Si X_train es DataFrame, conviértelo a numpy array\n",
    "    if hasattr(X_train, \"values\"):\n",
    "        train_vectors = X_train.values\n",
    "    else:\n",
    "        train_vectors = X_train\n",
    "    # Si y_train es Series, conviértelo a numpy array\n",
    "    if hasattr(y_train, \"values\"):\n",
    "        train_labels = y_train.values\n",
    "    else:\n",
    "        train_labels = y_train\n",
    "\n",
    "    for test_vector in X_test:\n",
    "        distances = np.sqrt(np.sum((train_vectors - test_vector) ** 2, axis=1))\n",
    "        k_indices = np.argsort(distances)[:k]\n",
    "        k_labels = train_labels[k_indices]\n",
    "        pred = np.bincount(k_labels).argmax()\n",
    "        predictions.append(pred)\n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec6519b",
   "metadata": {},
   "source": [
    "## Paso 9: Estandarizar (Z-score) y entrenar KNN, luego calcular accuracy  \n",
    "\n",
    "### Pasos:\n",
    "1. Aplicar **estandarización Z-score** a los datos de entrenamiento y test.  \n",
    "2. Entrenar el modelo KNN con los datos estandarizados.  \n",
    "3. Predecir las clases del conjunto de test.  \n",
    "4. Calcular el **accuracy** del modelo.  \n",
    "5. Guardar el resultado para la tabla comparativa.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3852d094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy KNN datos estandarizados: 0.7468\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Paso 9: Estandarizar (Z-score) y entrenar KNN, luego calcular accuracy\n",
    "\n",
    "# 1. Aplicar estandarización Z-score a los datos de entrenamiento y test\n",
    "scaler_z = StandardScaler()\n",
    "X_train_z = scaler_z.fit_transform(X_train)  # <-- Punto 1\n",
    "X_test_z = scaler_z.transform(X_test)        # <-- Punto 1\n",
    "\n",
    "# 2. Entrenar el modelo KNN manual con los datos estandarizados\n",
    "y_pred_z = knn_predict_manual(X_train_z, y_train.values.astype(int), X_test_z, k=k)  # <-- Punto 2\n",
    "\n",
    "# 3. Calcular el accuracy comparando predicciones con etiquetas reales\n",
    "accuracy_z = (y_pred_z == y_test.values).mean()  # <-- Punto 3\n",
    "\n",
    "# 4. Imprimir el resultado del accuracy\n",
    "print(f\"Accuracy KNN datos estandarizados: {accuracy_z:.4f}\")  # <-- Punto 4\n",
    "\n",
    "# 5. Guardar el resultado para la tabla comparativa\n",
    "accuracy_estandarizado = accuracy_z  # <-- Punto 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58946086",
   "metadata": {},
   "source": [
    "## Paso 10/11: Tabla comparativa de accuracies  \n",
    "\n",
    "### Pasos:\n",
    "1. Reunir los resultados de accuracy de cada experimento:  \n",
    "   - KNN sin escalar (80/20).  \n",
    "   - KNN normalizado (80/20).  \n",
    "   - KNN estandarizado (80/20).  \n",
    "2. Crear una tabla con los resultados.  \n",
    "3. Comparar el desempeño de cada método.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8df9711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Método  Accuracy\n",
      "0                    KNN crudo  0.810127\n",
      "1    KNN normalizado (Min-Max)  0.734177\n",
      "2  KNN estandarizado (Z-score)  0.746835\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Paso 10/11: Tabla comparativa de accuracies\n",
    "\n",
    "# 1. Reunir los resultados de accuracy de cada experimento\n",
    "acc_crudo = accuracy_crudo        # KNN sin escalar (80/20)\n",
    "acc_norm = accuracy_normalizado   # KNN normalizado (80/20)\n",
    "acc_z = accuracy_estandarizado    # KNN estandarizado (80/20)\n",
    "\n",
    "# 2. Crear una tabla con los resultados\n",
    "tabla_acc = pd.DataFrame({\n",
    "    'Método': ['KNN crudo', 'KNN normalizado (Min-Max)', 'KNN estandarizado (Z-score)'],\n",
    "    'Accuracy': [acc_crudo, acc_norm, acc_z]\n",
    "})\n",
    "\n",
    "# 3. Comparar el desempeño de cada método\n",
    "print(tabla_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cafd7a",
   "metadata": {},
   "source": [
    "---\n",
    "## Preguntas de reflexión y aplicación\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351bf383",
   "metadata": {},
   "source": [
    "1. ¿Por qué es importante normalizar o estandarizar los datos antes de usar KNN?  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82ee450",
   "metadata": {},
   "source": [
    "Es importante normalizar o estandarizar los datos antes de usar KNN porque este algoritmo\n",
    "#calcula distancias entre los puntos. Si las variables tienen escalas diferentes\n",
    "#(por ejemplo, edad en años y glucosa en mg/dL), las características con valores más grandes \n",
    "#pueden dominar el cálculo de la distancia y afectar el resultado. Normalizar o estandarizar\n",
    "#pone todas las variables en una escala similar, haciendo que el modelo sea más justo y preciso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3393faba",
   "metadata": {},
   "source": [
    "2. ¿Qué diferencias observaste en el accuracy entre los datos crudos, normalizados y estandarizados?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c6273f",
   "metadata": {},
   "source": [
    "Al comparar los resultados, el accuracy fue mayor usando los datos crudos que con los datos normalizado\n",
    "o estandarizados. Sin embargo, normalizar y estandarizar ayuda a que el modelo sea más justo cuando\n",
    "las variables tienen diferentes escalas. Aunque el accuracy bajó un poco, estos métodos suelen mejorar\n",
    "el desempeño en otros casos y hacen que el modelo sea más confiable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2743a4d",
   "metadata": {},
   "source": [
    "3. Si aumentamos el valor de **k** (número de vecinos), ¿cómo crees que cambiaría el rendimiento del modelo?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817198b3",
   "metadata": {},
   "source": [
    "Si aumentamos el valor de **k**, el modelo considerará más vecinos para decidir la clase. \n",
    "Esto puede hacer que las predicciones sean más estables y menos sensibles al ruido,\n",
    "pero si k es muy grande, el modelo puede perder precisión porque mezcla demasiados vecinos\n",
    "y puede ignorar patrones importantes. Lo ideal es probar varios valores y elegir el que mejor funcione."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a02e07",
   "metadata": {},
   "source": [
    "4. ¿Qué ventaja tiene implementar KNN manualmente antes de usar scikit-learn?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439b32f9",
   "metadata": {},
   "source": [
    "Implementar KNN manualmente ayuda a entender cómo funciona el algoritmo \"por dentro\": \n",
    "cómo se calculan las distancias, cómo se eligen los vecinos y cómo se decide la clase final.\n",
    "Así se puede ver cada paso y aprender el proceso, lo que facilita detectar errores y comprender\n",
    "mejor los resultados. Después, usar scikit-learn permite hacer lo mismo de forma más rápida\n",
    "y eficiente, pero ya sabiendo cómo funciona realmente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc53e18",
   "metadata": {},
   "source": [
    "5. ¿Qué limitaciones presenta KNN cuando se aplica a conjuntos de datos grandes o con muchas dimensiones?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76827e64",
   "metadata": {},
   "source": [
    "KNN tiene varias limitaciones en conjuntos de datos grandes o con muchas dimensiones. \n",
    "Cuando hay muchos datos, el cálculo de distancias para cada predicción se vuelve muy lento \n",
    "porque el algoritmo compara cada punto de testeo con todos los de entrenamiento. Además, \n",
    "si hay muchas variables (alta dimensión), las distancias entre puntos tienden a parecerse\n",
    "y el modelo pierde precisión, lo que se llama \"la maldición de la dimensionalidad\". \n",
    "Por eso, KNN no es ideal para datasets muy grandes o con muchas características."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5707edf3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bd6c9c",
   "metadata": {},
   "source": [
    "## Rúbrica de evaluación: Práctica KNN\n",
    "\n",
    "| Criterio | Descripción | Puntaje Máximo |\n",
    "|----------|-------------|----------------|\n",
    "| **1. Carga y exploración del dataset** | Carga correcta del archivo CSV, explicación de las variables y verificación de datos. | 15 pts |\n",
    "| **2. Implementación manual de KNN** | Código propio para calcular distancias euclidianas, selección de vecinos y votación mayoritaria. | 20 pts |\n",
    "| **3. Predicción individual (ejemplo aleatorio)** | Explicación clara del proceso paso a paso para un ejemplo de test. | 10 pts |\n",
    "| **4. Uso de scikit-learn (KNN)** | Entrenamiento y evaluación con `train_test_split`, comparación con el método manual. | 15 pts |\n",
    "| **5. Normalización y estandarización** | Aplicación correcta de Min-Max y Z-score, con cálculo de accuracy en cada caso. | 20 pts |\n",
    "| **6. Tabla comparativa de accuracies** | Presentación clara de los resultados y comparación entre métodos. | 10 pts |\n",
    "| **7. Reflexión y preguntas finales** | Respuestas a las preguntas de análisis planteadas (profundidad y claridad). | 10 pts |\n",
    "\n",
    "**Total: 100 pts**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
